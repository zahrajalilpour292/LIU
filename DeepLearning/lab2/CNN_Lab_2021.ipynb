{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Image Classification Laboration\n",
    "\n",
    "\n",
    "Images used in this laboration are from CIFAR 10 (https://en.wikipedia.org/wiki/CIFAR-10). The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. Your task is to make a classifier, using a convolutional neural network, that can correctly classify each image into the correct class.\n",
    "\n",
    "You need to answer all questions in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: What is a convolution\n",
    "\n",
    "To understand a bit more about convolutions, we will first test the convolution function in scipy using a number of classical filters. \n",
    "\n",
    "Convolve the image with Gaussian filter, a Sobel X filter, and a Sobel Y filter, using the function 'convolve2d' in 'signal' from scipy.\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html\n",
    "\n",
    "In a CNN, many filters are applied in each layer, and the filter coefficients are learned through back propagation (which is in contrast to traditional image processing, where the filters are designed by an expert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is finished\n",
    "\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "# Get a test image\n",
    "from scipy import misc\n",
    "image = misc.ascent()\n",
    "\n",
    "# Define a help function for creating a Gaussian filter\n",
    "def matlab_style_gauss2D(shape=(3,3),sigma=0.5):\n",
    "    \"\"\"\n",
    "    2D gaussian mask - should give the same result as MATLAB's\n",
    "    fspecial('gaussian',[shape],[sigma])\n",
    "    \"\"\"\n",
    "    m,n = [(ss-1.)/2. for ss in shape]\n",
    "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
    "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
    "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h\n",
    "\n",
    "# Create Gaussian filter with certain size and standard deviation\n",
    "gaussFilter = matlab_style_gauss2D((15,15),4)\n",
    "\n",
    "# Define filter kernels for SobelX and Sobely\n",
    "sobelX = np.array([[ 1, 0,  -1],\n",
    "                    [2, 0, -2],\n",
    "                    [1, 0, -1]]) \n",
    "\n",
    "sobelY = np.array([[ 1, 2,  1],\n",
    "                    [0, 0, 0],\n",
    "                    [-1, -2, -1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform convolution using the function 'convolve2d' for the different filters\n",
    "filterResponseGauss = \n",
    "filterResponseSobelX = \n",
    "filterResponseSobelY = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show filter responses\n",
    "fig, (ax_orig, ax_filt1, ax_filt2, ax_filt3) = plt.subplots(1, 4, figsize=(20, 6))\n",
    "ax_orig.imshow(image, cmap='gray')\n",
    "ax_orig.set_title('Original')\n",
    "ax_orig.set_axis_off()\n",
    "ax_filt1.imshow(np.absolute(filterResponseGauss), cmap='gray')\n",
    "ax_filt1.set_title('Filter response')\n",
    "ax_filt1.set_axis_off()\n",
    "ax_filt2.imshow(np.absolute(filterResponseSobelX), cmap='gray')\n",
    "ax_filt2.set_title('Filter response')\n",
    "ax_filt2.set_axis_off()\n",
    "ax_filt3.imshow(np.absolute(filterResponseSobelY), cmap='gray')\n",
    "ax_filt3.set_title('Filter response')\n",
    "ax_filt3.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2: Understanding convolutions\n",
    "\n",
    "Question 1: What do the 3 different filters (Gaussian, SobelX, SobelY) do to the original image?\n",
    "\n",
    "Question 2: What is the size of the original image? How many channels does it have? How many channels does a color image normally have?\n",
    "\n",
    "Question 3: What is the size of the different filters?\n",
    "\n",
    "Question 4: What is the size of the filter response if mode 'same' is used for the convolution ?\n",
    "\n",
    "Question 5: What is the size of the filter response if mode 'valid' is used for the convolution? How does the size of the valid filter response depend on the size of the filter? \n",
    "\n",
    "Question 6: Why are 'valid' convolutions a problem for CNNs with many layers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for checking sizes of image and filter responses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 3: Get a graphics card\n",
    "\n",
    "Skip this part if you run on a CPU\n",
    "\n",
    "Let's make sure that our script can see the graphics card that will be used. The graphics cards will perform all the time consuming convolutions in every training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore FutureWarning from numpy\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";\n",
    "\n",
    "# Allow growth of GPU memory, otherwise it will always look like all the memory is being used\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 4: How fast is the graphics card?\n",
    "\n",
    "Question 7: Why are the filters of size 7 x 7 x 3, and not 7 x 7 ? \n",
    "\n",
    "Question 8: What operation is performed by the 'Conv2D' layer? Is it a standard 2D convolution, as performed by the function signal.convolve2d we just tested?\n",
    "\n",
    "Lets investigate how much faster a convolution is with the graphics card (skip this part if you run on a CPU)\n",
    "\n",
    "Question 9: How much faster is the graphics card, compared to the CPU, for convolving a batch of 100 images?\n",
    "\n",
    "Question 10: How much faster is the graphics card, compared to the CPU, for convolving a batch of 2 images? Explain the difference compared to 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to compare processing time of CPU and GPU\n",
    "\n",
    "import timeit\n",
    "\n",
    "n_images_in_batch = 100\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "# Perform convolutions using the CPU\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_images = tf.random.normal((n_images_in_batch, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_images)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "# Perform convolutions using the GPU (graphics card)\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_images = tf.random.normal((n_images_in_batch, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_images)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()\n",
    "\n",
    "# Run the convolution several times and measure the time\n",
    "print('Time (s) to convolve 32 filters of size 7 x 7 x 3 over 100 random images of size 100 x 100 x 3'\n",
    "      ' (batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 5:  Load data\n",
    "Time to make a 2D CNN. Load the images and labels from keras.datasets, this cell is already finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Download CIFAR train and test data\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = cifar10.load_data()\n",
    "\n",
    "print(\"Training images have size {} and labels have size {} \".format(Xtrain.shape, Ytrain.shape))\n",
    "print(\"Test images have size {} and labels have size {} \\n \".format(Xtest.shape, Ytest.shape))\n",
    "\n",
    "# Reduce the number of images for training and testing to 10000 and 2000 respectively, \n",
    "# to reduce processing time for this laboration\n",
    "Xtrain = Xtrain[0:10000]\n",
    "Ytrain = Ytrain[0:10000]\n",
    "\n",
    "Xtest = Xtest[0:2000]\n",
    "Ytest = Ytest[0:2000]\n",
    "\n",
    "Ytestint = Ytest\n",
    "\n",
    "print(\"Reduced training images have size %s and labels have size %s \" % (Xtrain.shape, Ytrain.shape))\n",
    "print(\"Reduced test images have size %s and labels have size %s \\n\" % (Xtest.shape, Ytest.shape))\n",
    "\n",
    "# Check that we have some training examples from each class\n",
    "for i in range(10):\n",
    "    print(\"Number of training examples for class {} is {}\" .format(i,np.sum(Ytrain == i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 6: Plotting\n",
    "\n",
    "Lets look at some of the training examples, this cell is already finished. You will see different examples every time you run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range(18):\n",
    "    idx = np.random.randint(7500)\n",
    "    label = Ytrain[idx,0]\n",
    "    \n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(Xtrain[idx])\n",
    "    plt.title(\"Class: {} ({})\".format(label, classes[label]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Part 7: Split data into training, validation and testing\n",
    "Split your training data into training (Xtrain, Ytrain) and validation (Xval, Yval), so that we have training, validation and test datasets (as in the previous laboration). We use a function in scikit learn. Use 25% of the data for validation.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Print the size of training data, validation data and test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 8: Preprocessing of images\n",
    "\n",
    "Lets perform some preprocessing. The images are stored as uint8, i.e. 8 bit unsigned integers, but need to be converted to 32 bit floats. We also make sure that the range is -1 to 1, instead of 0 - 255. This cell is already finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datatype for Xtrain, Xval, Xtest, to float32\n",
    "Xtrain = Xtrain.astype('float32')\n",
    "Xval = Xval.astype('float32')\n",
    "Xtest = Xtest.astype('float32')\n",
    "\n",
    "# Change range of pixel values to [-1,1]\n",
    "Xtrain = Xtrain / 127.5 - 1\n",
    "Xval = Xval / 127.5 - 1\n",
    "Xtest = Xtest / 127.5 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 9: Preprocessing of labels\n",
    "\n",
    "The labels (Y) need to be converted from e.g. '4' to \"hot encoded\", i.e. to a vector of type [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] . We use a function in Keras, see https://keras.io/api/utils/python_utils/#to_categorical-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Print shapes before converting the labels\n",
    "\n",
    "\n",
    "# Your code for converting Ytrain, Yval, Ytest to categorical\n",
    "\n",
    "\n",
    "# Print shapes after converting the labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 10: 2D CNN\n",
    "Finish this code to create the image classifier, using a 2D CNN. Each convolutional layer will contain 2D convolution, batch normalization and max pooling. After the convolutional layers comes a flatten layer and a number of intermediate dense layers. The convolutional layers should take the number of filters as an argument, use a kernel size of 3 x 3, 'same' padding, and relu activation functions. The number of filters will double with each convolutional layer. The max pooling layers should have a pool size of 2 x 2. The intermediate dense layers before the final dense layer should take the number of nodes as an argument, use relu activation functions, and be followed by batch normalization. The final dense layer should have 10 nodes (= the number of classes in this laboration) and 'softmax' activation. Here we start with the Adam optimizer.\n",
    "\n",
    "Relevant functions are\n",
    "\n",
    "`model.add()`, adds a layer to the network\n",
    "\n",
    "`Dense()`, a dense network layer\n",
    "\n",
    "`Conv2D()`, performs 2D convolutions with a number of filters with a certain size (e.g. 3 x 3). \n",
    "\n",
    "`BatchNormalization()`, perform batch normalization\n",
    "\n",
    "`MaxPooling2D()`, saves the max for a given pool size, results in down sampling\n",
    "\n",
    "`Flatten()`, flatten a multi-channel tensor into a long vector\n",
    "\n",
    "`model.compile()`, compile the model, add \" metrics=['accuracy'] \" to print the classification accuracy during the training\n",
    "\n",
    "See https://keras.io/api/layers/core_layers/dense/ and https://keras.io/api/layers/reshaping_layers/flatten/ for information on how the `Dense()` and `Flatten()` functions work\n",
    "\n",
    "See https://keras.io/layers/convolutional/ for information on how `Conv2D()` works\n",
    "\n",
    "See https://keras.io/layers/pooling/ for information on how `MaxPooling2D()` works\n",
    "\n",
    "Import a relevant cost function for multi-class classification from keras.losses (https://keras.io/losses/)\n",
    "\n",
    "See the following links for how to compile, train and evaluate the model\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#compile-method\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#fit-method\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#evaluate-method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import ?\n",
    "\n",
    "# Set seed from random number generator, for better comparisons\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "\n",
    "def build_CNN(input_shape, n_conv_layers=2, n_filters=16, n_dense_layers=0, n_nodes=50, use_dropout=False, learning_rate=0.01):\n",
    "\n",
    "    # Setup a sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add first convolutional layer to the model, requires input shape\n",
    "    \n",
    "    # Add remaining convolutional layers to the model, the number of filters should increase a factor 2 for each layer\n",
    "    for i in range(n_conv_layers-1):\n",
    "    \n",
    "    # Add flatten layer\n",
    "    \n",
    "    # Add intermediate dense layers\n",
    "    for i in range(n_dense_layers):\n",
    "        \n",
    "    # Add final dense layer\n",
    "   \n",
    "    # Compile model\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a help function for plotting the training results\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_results(history):\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    acc = history.history['accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.legend(['Training','Validation'])\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(acc)\n",
    "    plt.plot(val_acc)\n",
    "    plt.legend(['Training','Validation'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11: Train 2D CNN\n",
    "\n",
    "Time to train the 2D CNN, start with 2 convolutional layers, no intermediate dense layers, learning rate = 0.01. The first convolutional layer should have 16 filters (which means that the second convolutional layer will have 32 filters).\n",
    "\n",
    "Relevant functions\n",
    "\n",
    "`build_CNN`, the function we defined in Part 10, call it with the parameters you want to use\n",
    "\n",
    "`model.fit()`, train the model with some training data\n",
    "\n",
    "`model.evaluate()`, apply the trained model to some test data\n",
    "\n",
    "See the following links for how to train and evaluate the model\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#fit-method\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#evaluate-method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 convolutional layers, no intermediate dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "input_shape = ?\n",
    "\n",
    "# Build model\n",
    "model1 = \n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = \n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12: Improving performance\n",
    "\n",
    "Skip question 12 if you run on a CPU\n",
    "\n",
    "Write down the test accuracy, are you satisfied with the classifier performance (random chance is 10%) ? \n",
    "\n",
    "Question 11: How big is the difference between training and test accuracy?\n",
    "\n",
    "Question 12: How busy is the GPU for a batch size of 100? How much GPU memory is used? Hint: run 'watch nvidia-smi' on the cloud computer during training. \n",
    "\n",
    "Question 13: For the DNN laboration we used a batch size of 10,000, why do we need to use a smaller batch size in this laboration?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 convolutional layers, 1 intermediate dense layer (50 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "input_shape = ?\n",
    "\n",
    "# Build model\n",
    "model2 = \n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = \n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 convolutional layers, 1 intermediate dense layer (50 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "input_shape = ?\n",
    "\n",
    "# Build model\n",
    "model3 = \n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history3 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = \n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 13: Plot the CNN architecture\n",
    "\n",
    "To understand your network better, print the architecture using `model.summary()`\n",
    "\n",
    "Question 14: How many trainable parameters does your network have? Which part of the network contains most of the parameters?\n",
    "\n",
    "Question 15: What is the input to and output of a Conv2D layer? What are the dimensions of the input and output? \n",
    "\n",
    "Question 16: Is the batch size always the first dimension of each 4D tensor? Check the documentation for Conv2D, https://keras.io/layers/convolutional/\n",
    "\n",
    "Question 17: If a convolutional layer that contains 128 filters is applied to an input with 32 channels, what is the number of channels in the output?\n",
    "\n",
    "Question 18: Why is the number of parameters in each Conv2D layer *not* equal to the number of filters times the number of filter coefficients per filter (plus biases)?\n",
    "\n",
    "Question 19: How does MaxPooling help in reducing the number of parameters to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print network architecture\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 14: Dropout regularization\n",
    "\n",
    "Add dropout regularization to each intermediate dense layer, dropout probability 50%.\n",
    "\n",
    "Question 20: How much did the test accuracy improve with dropout, compared to without dropout?\n",
    "\n",
    "Question 21: What other types of regularization can be applied? How can you add L2 regularization for the convolutional layers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 convolutional layers, 1 intermediate dense layer (50 nodes), dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "input_shape = ?\n",
    "\n",
    "# Build model\n",
    "model4 = \n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history4 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = \n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 15: Tweaking performance\n",
    "\n",
    "You have now seen the basic building blocks of a 2D CNN. To further improve performance involves changing the number of convolutional layers, the number of filters per layer, the number of intermediate dense layers, the number of nodes in the intermediate dense layers, batch size, learning rate, number of epochs, etc. Spend some time (30 - 90 minutes) testing different settings.\n",
    "\n",
    "Question 22: How high test accuracy can you obtain? What is your best configuration?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your best config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "\n",
    "# Build model\n",
    "model5 =\n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history5 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = \n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 16: Rotate the test images\n",
    "\n",
    "How high is the test accuracy if we rotate the test images? In other words, how good is the CNN at generalizing to rotated images?\n",
    "\n",
    "Rotate each test image 90 degrees, the cells are already finished.\n",
    "\n",
    "Question 23: What is the test accuracy for rotated test images, compared to test images without rotation? Explain the difference in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myrotate(images):\n",
    "\n",
    "    images_rot = np.rot90(images, axes=(1,2))\n",
    "    \n",
    "    return images_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate the test images 90 degrees\n",
    "Xtest_rotated = myrotate(Xtest)\n",
    "\n",
    "# Look at some rotated images\n",
    "plt.figure(figsize=(16,4))\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(500)\n",
    "    \n",
    "    plt.subplot(2,10,i+1)\n",
    "    plt.imshow(Xtest[idx]/2+0.5)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2,10,i+11)\n",
    "    plt.imshow(Xtest_rotated[idx]/2+0.5)\n",
    "    plt.title(\"Rotated\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on rotated test set\n",
    "score = \n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 17: Augmentation using Keras `ImageDataGenerator`\n",
    "\n",
    "We can increase the number of training images through data augmentation (we now ignore that CIFAR10 actually has 60 000 training images). Image augmentation is about creating similar images, by performing operations such as rotation, scaling, elastic deformations and flipping of existing images. This will prevent overfitting, especially if all the training images are in a certain orientation.\n",
    "\n",
    "We will perform the augmentation on the fly, using a built-in function in Keras, called `ImageDataGenerator`\n",
    "\n",
    "See https://keras.io/preprocessing/image/ , the `flow` method should be used\n",
    "\n",
    "Do *NOT* use use_multiprocessing=True here, as it can cause strange errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all 60 000 training images again. ImageDataGenerator manages validation data on its own\n",
    "(Xtrain, Ytrain), _ = cifar10.load_data()\n",
    "\n",
    "# Reduce number of images to 10,000\n",
    "Xtrain = Xtrain[0:10000]\n",
    "Ytrain = Ytrain[0:10000]\n",
    "\n",
    "# Change data type and rescale range\n",
    "Xtrain = Xtrain.astype('float32')\n",
    "Xtrain = Xtrain / 127.5 - 1\n",
    "\n",
    "# Convert labels to hot encoding\n",
    "Ytrain = to_categorical(Ytrain, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a data generator with on-the-fly data augmentation, 20% validation split\n",
    "# Use a rotation range of 30 degrees, horizontal and vertical flipping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "# Setup a flow for training data, assume that we can fit all images into CPU memory\n",
    "\n",
    "\n",
    "# Setup a flow for validation data, assume that we can fit all images into CPU memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 18: What about big data?\n",
    "\n",
    "Question 24: How would you change the code for the image generator if you cannot fit all training images in CPU memory? What is the disadvantage of doing that change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some augmented images\n",
    "plot_datagen = datagen.flow(Xtrain, Ytrain, batch_size=1)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range(18):\n",
    "    (im, label) = plot_datagen.next()\n",
    "    im = (im[0] + 1) * 127.5\n",
    "    im = im.astype('int')\n",
    "    label = np.flatnonzero(label)[0]\n",
    "    \n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"Class: {} ({})\".format(label, classes[label]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 19: Train the CNN with images from the generator\n",
    "\n",
    "See https://keras.io/api/models/model_training_apis/#fit-method for how to use model.fit with a generator instead of a fix dataset (numpy arrays)\n",
    "\n",
    "To make the comparison fair to training without augmentation\n",
    "\n",
    "    steps_per_epoch should be set to: len(Xtrain)*(1 - validation_split)/batch_size\n",
    "\n",
    "    validation_steps should be set to: len(Xtrain)*validation_split/batch_size\n",
    "\n",
    "Question 25: How quickly is the training accuracy increasing compared to without augmentation? Explain why there is a difference compared to without augmentation. What parameter is necessary to change to perform more training?\n",
    "\n",
    "Question 26: What other types of image augmentation can be applied, compared to what we use here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 100\n",
    "epochs = 200\n",
    "input_shape = ?\n",
    "\n",
    "# Build model (your best config)\n",
    "model6 = \n",
    "\n",
    "validation_split=0.2\n",
    "    \n",
    "# Train the model using on the fly augmentation\n",
    "history6 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is still a big difference in accuracy for original and rotated test images\n",
    "\n",
    "# Evaluate the trained model on original test set\n",
    "score = model6.evaluate(Xtest, Ytest, batch_size = batch_size, verbose=0)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])\n",
    "\n",
    "# Evaluate the trained model on rotated test set\n",
    "score = model6.evaluate(Xtest_rotated, Ytest, batch_size = batch_size, verbose=0)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 20: Plot misclassified images\n",
    "\n",
    "Lets plot some images where the CNN performed badly, these cells are already finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassified images\n",
    "y_pred = model6.predict_classes(Xtest)\n",
    "y_correct = np.argmax(Ytest,axis=-1)\n",
    "\n",
    "miss = np.flatnonzero(y_correct != y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few of them\n",
    "plt.figure(figsize=(15,4))\n",
    "perm = np.random.permutation(miss)\n",
    "for i in range(18):\n",
    "    im = (Xtest[perm[i]] + 1) * 127.5\n",
    "    im = im.astype('int')\n",
    "    label_correct = y_correct[perm[i]]\n",
    "    label_pred = y_pred[perm[i]]\n",
    "    \n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"{}, classified as {}\".format(classes[label_correct], classes[label_pred]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 21: Testing on another size\n",
    "\n",
    "Question 27: This CNN has been trained on 32 x 32 images, can it be applied to images of another size? If not, why is this the case?\n",
    "\n",
    "Question 28: Is it possible to design a CNN that can be trained on images of one size, and then applied to an image of any size? How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 22: Pre-trained 2D CNNs\n",
    "\n",
    "There are many deep 2D CNNs that have been pre-trained using the large ImageNet database (several million images, 1000 classes). Import a pre-trained ResNet50 network from Keras applications. Show the network using `model.summary()`\n",
    "\n",
    "Question 29: How many convolutional layers does ResNet50 have? \n",
    "\n",
    "Question 30: How many trainable parameters does the ResNet50 network have? \n",
    "\n",
    "Question 31: What is the size of the images that ResNet50 expects as input?\n",
    "\n",
    "Question 32: Using the answer to question 30, explain why the second derivative is seldom used when training deep networks.\n",
    "\n",
    "Apply the pre-trained CNN to 5 random color images that you download and copy to the cloud machine or your own computer. Are the predictions correct? How certain is the network of each image class?\n",
    "\n",
    "These pre-trained networks can be fine tuned to your specific data, and normally only the last layers need to be re-trained, but it will still be too time consuming to do in this laboration.\n",
    "\n",
    "See https://keras.io/api/applications/ and https://keras.io/api/applications/resnet/#resnet50-function \n",
    "\n",
    "Useful functions\n",
    "\n",
    "`image.load_img` in keras.preprocessing\n",
    "\n",
    "`image.img_to_array` in keras.preprocessing\n",
    "\n",
    "`ResNet50` in keras.applications.resnet50\n",
    "\n",
    "`preprocess_input` in keras.applications.resnet50\n",
    "\n",
    "`decode_predictions` in keras.applications.resnet50\n",
    "\n",
    "`expand_dims` in numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for using pre-trained ResNet 50 on 5 color images of your choice. \n",
    "# The preprocessing should transform the image to a size that is expected by the CNN.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
